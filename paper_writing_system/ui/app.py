"""
Streamlit ì›¹ UI
ë…¼ë¬¸ ì‘ì„± ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import sys
import os
import asyncio
import logging
from pathlib import Path

import streamlit as st

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from config.settings import Settings
from core.pdf_processor import PDFProcessor
from core.rag_engine import RAGEngine
from core.state_manager import (
    PaperTopic,
    get_sections_for_format,
    IEEE_SECTIONS,
    ACM_SECTIONS,
)
from graph.workflow import PaperWritingWorkflow

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="Academic Paper Writing Agent",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded",
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        "settings": None,
        "rag_engine": None,
        "workflow": None,
        "is_initialized": False,
        "is_indexing": False,
        "is_generating": False,
        "generation_logs": [],
        "final_state": None,
        "index_stats": None,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


init_session_state()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì´ˆê¸°í™” í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def initialize_system(api_key: str, data_path: str):
    """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    os.environ["ANTHROPIC_API_KEY"] = api_key

    settings = Settings(
        anthropic_api_key=api_key,
        data_path=data_path,
    )

    rag_engine = RAGEngine(
        embedding_model_name=settings.embedding_model,
        vector_store_path=settings.get_vector_store_path(),
    )
    rag_engine.initialize()

    st.session_state.settings = settings
    st.session_state.rag_engine = rag_engine
    st.session_state.is_initialized = True
    st.session_state.index_stats = rag_engine.get_index_stats()


def index_papers(data_path: str, force: bool = False):
    """PDF ë…¼ë¬¸ ì¸ë±ì‹±"""
    st.session_state.is_indexing = True

    settings = st.session_state.settings
    rag_engine = st.session_state.rag_engine

    if force:
        rag_engine.clear_index()

    processor = PDFProcessor(
        chunk_size=settings.pdf_chunk_size,
        chunk_overlap=settings.pdf_chunk_overlap,
    )
    cache_dir = settings.get_vector_store_path() / "cache"
    processor.set_cache_dir(cache_dir)

    data_dir = Path(data_path)
    chunks = processor.process_directory(data_dir, force_reprocess=force)

    if chunks:
        rag_engine.index_documents(chunks)

    st.session_state.index_stats = rag_engine.get_index_stats()
    st.session_state.is_indexing = False


async def generate_paper(topic: PaperTopic):
    """ë…¼ë¬¸ ìƒì„± ì‹¤í–‰"""
    settings = st.session_state.settings
    rag_engine = st.session_state.rag_engine

    workflow = PaperWritingWorkflow(
        settings=settings,
        rag_engine=rag_engine,
    )

    st.session_state.generation_logs = []
    st.session_state.is_generating = True

    def log_callback(node_name: str, message: str):
        st.session_state.generation_logs.append(
            f"[{node_name}] {message}"
        )

    final_state = await workflow.run(topic, callback=log_callback)
    st.session_state.final_state = final_state
    st.session_state.is_generating = False

    return final_state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def render_sidebar():
    """ì‚¬ì´ë“œë°” ë Œë”ë§"""
    with st.sidebar:
        st.title("Settings")

        # API í‚¤ ì…ë ¥
        api_key = st.text_input(
            "Anthropic API Key",
            type="password",
            help="Claude API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        )

        # ë°ì´í„° ê²½ë¡œ
        default_data_path = str(
            PROJECT_ROOT.parent / "data"
        )
        data_path = st.text_input(
            "Data Directory",
            value=default_data_path,
            help="ì—°êµ¬ ë…¼ë¬¸ PDFê°€ ìˆëŠ” ë””ë ‰í„°ë¦¬ ê²½ë¡œ",
        )

        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button(
            "Initialize System",
            disabled=not api_key,
            type="primary",
        ):
            with st.spinner("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
                try:
                    initialize_system(api_key, data_path)
                    st.success("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
                except Exception as e:
                    st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        st.divider()

        # ì¸ë±ìŠ¤ ìƒíƒœ
        st.subheader("Knowledge Base")

        if st.session_state.is_initialized:
            stats = st.session_state.index_stats
            if stats:
                st.metric(
                    "Indexed Chunks",
                    stats.get("total_chunks", 0),
                )
                st.metric(
                    "Unique Files",
                    stats.get("total_unique_files", 0),
                )

                # ë””ë ‰í„°ë¦¬ë³„ ë¶„í¬
                dirs = stats.get("chunks_by_directory", {})
                if dirs:
                    with st.expander("Directory Breakdown"):
                        for d, count in sorted(
                            dirs.items(),
                            key=lambda x: x[1],
                            reverse=True,
                        ):
                            st.text(f"  {d}: {count}")

            col1, col2 = st.columns(2)
            with col1:
                if st.button("Index Papers"):
                    with st.spinner("ì¸ë±ì‹± ì¤‘..."):
                        index_papers(data_path)
                    st.rerun()
            with col2:
                if st.button("Re-index"):
                    with st.spinner("ì¬ì¸ë±ì‹± ì¤‘..."):
                        index_papers(data_path, force=True)
                    st.rerun()
        else:
            st.info("ì‹œìŠ¤í…œì„ ë¨¼ì € ì´ˆê¸°í™”í•˜ì„¸ìš”.")

        st.divider()

        # ë…¼ë¬¸ ì„¤ì •
        st.subheader("Paper Config")
        paper_format = st.selectbox(
            "Format",
            options=["ieee", "acm"],
            index=0,
        )
        language = st.selectbox(
            "Language",
            options=["en", "ko"],
            format_func=lambda x: "English" if x == "en" else "Korean",
        )

        return paper_format, language, data_path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ì˜ì—­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def render_main(paper_format: str, language: str):
    """ë©”ì¸ ì˜ì—­ ë Œë”ë§"""
    st.title("Academic Paper Writing Agent")
    st.caption(
        "LangGraph + Claude API ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ë…¼ë¬¸ ì‘ì„± ì‹œìŠ¤í…œ"
    )

    # íƒ­ êµ¬ì„±
    tab_input, tab_result, tab_evidence, tab_verify, tab_export = st.tabs(
        ["Input", "Generated Paper", "Evidence", "Verification", "Export"]
    )

    # â”€â”€ Input íƒ­ â”€â”€
    with tab_input:
        render_input_tab(paper_format, language)

    # â”€â”€ Generated Paper íƒ­ â”€â”€
    with tab_result:
        render_result_tab()

    # â”€â”€ Evidence íƒ­ â”€â”€
    with tab_evidence:
        render_evidence_tab()

    # â”€â”€ Verification íƒ­ â”€â”€
    with tab_verify:
        render_verification_tab()

    # â”€â”€ Export íƒ­ â”€â”€
    with tab_export:
        render_export_tab()


def render_input_tab(paper_format: str, language: str):
    """ì…ë ¥ íƒ­ ë Œë”ë§"""
    st.subheader("Paper Topic")

    title = st.text_input(
        "Paper Title",
        placeholder="ì˜ˆ: LLM-based Network AIOps: A Comprehensive Framework",
    )
    research_focus = st.text_area(
        "Research Focus",
        placeholder="ì´ ì—°êµ¬ì˜ í•µì‹¬ ì§ˆë¬¸ê³¼ ëª©í‘œë¥¼ ê¸°ìˆ í•˜ì„¸ìš”...",
        height=100,
    )
    keywords_input = st.text_input(
        "Keywords (comma-separated)",
        placeholder="ì˜ˆ: AIOps, LLM, Network Management, Log Analysis",
    )

    # ì„¹ì…˜ ì„ íƒ
    available_sections = get_sections_for_format(paper_format)
    selected_sections = st.multiselect(
        "Target Sections",
        options=available_sections,
        default=available_sections,
    )

    # ì§„í–‰ ìƒí™© í‘œì‹œ
    st.divider()
    st.subheader("Progress")

    # ë¡œê·¸ í‘œì‹œ ì˜ì—­
    log_container = st.container()
    with log_container:
        if st.session_state.generation_logs:
            for log in st.session_state.generation_logs:
                st.text(log)

    # ìƒì„± ë²„íŠ¼
    st.divider()
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        start_disabled = (
            not st.session_state.is_initialized
            or not title
            or not research_focus
            or st.session_state.is_generating
        )
        if st.button(
            "Start Writing",
            type="primary",
            disabled=start_disabled,
        ):
            keywords = [
                k.strip() for k in keywords_input.split(",") if k.strip()
            ]
            topic = PaperTopic(
                title=title,
                research_focus=research_focus,
                keywords=keywords,
                target_sections=selected_sections,
                paper_format=paper_format,
                language=language,
            )

            with st.spinner("ë…¼ë¬¸ ìƒì„± ì¤‘... (ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                result = asyncio.run(generate_paper(topic))
                st.session_state.final_state = result

            st.rerun()

    with col2:
        if st.button("Reset", disabled=st.session_state.is_generating):
            st.session_state.final_state = None
            st.session_state.generation_logs = []
            st.rerun()

    if not st.session_state.is_initialized:
        st.warning(
            "ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ê³  ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ì„¸ìš”."
        )


def render_result_tab():
    """ìƒì„±ëœ ë…¼ë¬¸ íƒ­"""
    state = st.session_state.final_state

    if not state:
        st.info("ë…¼ë¬¸ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    final_paper = state.get("final_paper")
    draft = state.get("draft")

    if final_paper:
        st.markdown(final_paper)
    elif draft:
        for section in draft.get("sections", []):
            with st.expander(
                f"{section['name']} ({section.get('word_count', 0)} words)",
                expanded=True,
            ):
                st.markdown(section.get("content", ""))

        # ì°¸ê³ ë¬¸í—Œ
        refs = draft.get("references", [])
        if refs:
            st.subheader("References")
            for ref in refs:
                st.text(ref)
    else:
        st.warning("ë…¼ë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        error = state.get("error_message")
        if error:
            st.error(error)


def render_evidence_tab():
    """ê·¼ê±° íƒ­"""
    state = st.session_state.final_state

    if not state:
        st.info("ê·¼ê±°ê°€ ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    evidence = state.get("research_evidence")
    if not evidence:
        st.warning("ê·¼ê±° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.subheader("Evidence Summary")
    st.markdown(evidence.get("evidence_summary", ""))

    st.subheader("Relevant Papers")
    papers = evidence.get("relevant_papers", [])
    for paper in papers:
        with st.expander(
            f"{paper.get('citation_key', '')} {paper.get('title', 'Unknown')}"
        ):
            st.text(f"Authors: {paper.get('authors', 'Unknown')}")
            st.text(f"Source: {paper.get('source', '')}")
            st.markdown(f"**Key Findings:** {paper.get('key_findings', '')}")
            st.markdown(f"**Methodology:** {paper.get('methodology', '')}")
            st.markdown(f"**Relevance:** {paper.get('relevance', '')}")

    st.subheader("Research Gaps")
    gaps = evidence.get("research_gaps", [])
    for gap in gaps:
        st.markdown(f"- {gap}")

    st.subheader("Search Queries Used")
    queries = evidence.get("search_queries_used", [])
    for q in queries:
        st.text(f"  - {q}")


def render_verification_tab():
    """ê²€ì¦ íƒ­"""
    state = st.session_state.final_state

    if not state:
        st.info("ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    verification = state.get("verification")
    if not verification:
        st.warning("ê²€ì¦ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ì ìˆ˜ ëŒ€ì‹œë³´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        score = verification.get("overall_score", 0)
        st.metric("Overall Score", f"{score:.2f}")
    with col2:
        st.metric(
            "Consistency",
            f"{verification.get('consistency_score', 0):.2f}",
        )
    with col3:
        st.metric(
            "Citation Accuracy",
            f"{verification.get('citation_accuracy_score', 0):.2f}",
        )
    with col4:
        st.metric(
            "Quality",
            f"{verification.get('quality_score', 0):.2f}",
        )

    is_valid = verification.get("is_valid", False)
    if is_valid:
        st.success("ê²€ì¦ í†µê³¼!")
    else:
        st.warning("ê²€ì¦ ë¯¸í†µê³¼ - ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # ì´ìŠˆ ëª©ë¡
    st.subheader("Issues Found")
    issues = verification.get("issues", [])

    if not issues:
        st.info("ë°œê²¬ëœ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for issue in issues:
            severity = issue.get("severity", "medium")
            icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                severity, "âšª"
            )
            with st.expander(
                f"{icon} [{severity.upper()}] {issue.get('section', '')} - "
                f"{issue.get('issue_type', '')}"
            ):
                st.markdown(f"**Description:** {issue.get('description', '')}")
                st.markdown(f"**Suggestion:** {issue.get('suggestion', '')}")

    # ê°œì„  ì œì•ˆ
    suggestions = verification.get("improvement_suggestions", [])
    if suggestions:
        st.subheader("Improvement Suggestions")
        for s in suggestions:
            st.markdown(f"- {s}")


def render_export_tab():
    """ë‚´ë³´ë‚´ê¸° íƒ­"""
    state = st.session_state.final_state

    if not state:
        st.info("ë‚´ë³´ë‚¼ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    final_paper = state.get("final_paper", "")
    if not final_paper:
        st.warning("ìµœì¢… ë…¼ë¬¸ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    st.subheader("Export Options")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.download_button(
            label="Download as Markdown",
            data=final_paper,
            file_name="paper.md",
            mime="text/markdown",
        )

    with col2:
        st.download_button(
            label="Download as Text",
            data=final_paper,
            file_name="paper.txt",
            mime="text/plain",
        )

    with col3:
        st.info("DOCX/PDF export ê¸°ëŠ¥ì€ ì¶”í›„ ì¶”ê°€ ì˜ˆì •")

    st.divider()
    st.subheader("Preview")
    st.markdown(final_paper)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    """ë©”ì¸ ì•± ì‹¤í–‰"""
    paper_format, language, data_path = render_sidebar()
    render_main(paper_format, language)


if __name__ == "__main__":
    main()
else:
    main()
